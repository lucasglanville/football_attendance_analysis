{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bf1a4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8cdba4",
   "metadata": {},
   "source": [
    "# First, try to scrape attendance value from specific match URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f44f477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for: https://www.worldfootball.net/report/eerste-klasse-a-2022-2023-krc-genk-sv-zulte-waregem/\n",
      "Attendance: 14.111\n",
      "--------------------\n",
      "Fetching data for: https://www.worldfootball.net/report/league-one-2007-2008-millwall-fc-tranmere-rovers/\n",
      "Attendance: 8.925\n",
      "--------------------\n",
      "Fetching data for: https://www.worldfootball.net/report/league-one-2020-2021-ipswich-town-fleetwood-town/\n",
      "Attendance: without spectators.\n",
      "--------------------\n",
      "Fetching data for: https://www.worldfootball.net/report/first-division-2016-2017-apoel-nikosia-anorthosis-famagusta-fc/\n",
      "Attendance not found.\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "# These test URLS contain 22/23 Belgium 1st div game, 07/08 English League One game,\n",
    "# 20/21 (covid!) English League One game, 16/17 Cyprus 1st div game\n",
    "\n",
    "urls = [\n",
    "    \"https://www.worldfootball.net/report/eerste-klasse-a-2022-2023-krc-genk-sv-zulte-waregem/\",\n",
    "    \"https://www.worldfootball.net/report/league-one-2007-2008-millwall-fc-tranmere-rovers/\",\n",
    "    \"https://www.worldfootball.net/report/league-one-2020-2021-ipswich-town-fleetwood-town/\",\n",
    "    \"https://www.worldfootball.net/report/first-division-2016-2017-apoel-nikosia-anorthosis-famagusta-fc/\"\n",
    "]\n",
    "\n",
    "# Loop to scrape attendance figures from URL list:\n",
    "\n",
    "for URL in urls:\n",
    "    print(f\"Fetching data for: {URL}\")\n",
    "\n",
    "    # Fetch the webpage\n",
    "    response = requests.get(URL)\n",
    "    response.raise_for_status()  # Will raise an exception if there's an error\n",
    "\n",
    "    # Parse the content using BeautifulSoup\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    results = soup.find(id=\"site\").find_all(\"td\", class_=\"dunkel\")\n",
    "\n",
    "    attendance_td = None\n",
    "    for i, td in enumerate(results):\n",
    "        img = td.find('img', title='Attendance')\n",
    "        if img:\n",
    "            attendance_td = results[i + 1]  # Get the next <td> element after the img\n",
    "            break\n",
    "\n",
    "    if attendance_td:\n",
    "        attendance = attendance_td.get_text(strip=True)\n",
    "        print(f\"Attendance: {attendance}\")\n",
    "    else:\n",
    "        print(\"Attendance not found.\")\n",
    "    print(\"--------------------\")  # To separate results for clarity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c2f293",
   "metadata": {},
   "source": [
    "# Next, try to scrape attendance values from all matches in specific game week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27ff18a4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for: https://www.worldfootball.net/report/ligue-2-2018-2019-gfc-ajaccio-us-orleans/\n",
      "Attendance: 2.498\n",
      "--------------------\n",
      "Fetching data for: https://www.worldfootball.net/report/ligue-2-2018-2019-lb-chateauroux-estac-troyes/\n",
      "Attendance: 6.861\n",
      "--------------------\n",
      "Fetching data for: https://www.worldfootball.net/report/ligue-2-2018-2019-grenoble-foot-38-clermont-foot/\n",
      "Attendance: 6.389\n",
      "--------------------\n",
      "Fetching data for: https://www.worldfootball.net/report/ligue-2-2018-2019-le-havre-ac-as-beziers/\n",
      "Attendance: 5.297\n",
      "--------------------\n",
      "Fetching data for: https://www.worldfootball.net/report/ligue-2-2018-2019-fc-lorient-as-nancy/\n",
      "Attendance: 6.952\n",
      "--------------------\n",
      "Fetching data for: https://www.worldfootball.net/report/ligue-2-2018-2019-chamois-niortais-paris-fc/\n",
      "Attendance: 3.397\n",
      "--------------------\n",
      "Fetching data for: https://www.worldfootball.net/report/ligue-2-2018-2019-red-star-fc-ac-ajaccio/\n",
      "Attendance: 1.863\n",
      "--------------------\n",
      "Fetching data for: https://www.worldfootball.net/report/ligue-2-2018-2019-valenciennes-fc-stade-brest/\n",
      "Attendance: 7.557\n",
      "--------------------\n",
      "Fetching data for: https://www.worldfootball.net/report/ligue-2-2018-2019-aj-auxerre-rc-lens/\n",
      "Attendance: 10.404\n",
      "--------------------\n",
      "Fetching data for: https://www.worldfootball.net/report/ligue-2-2018-2019-fc-sochaux-fc-metz/\n",
      "Attendance: 6.865\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "URL = \"https://www.worldfootball.net/schedule/fra-ligue-2-2018-2019-spieltag/10/\"\n",
    "\n",
    "# Fetch the webpage\n",
    "response = requests.get(URL)\n",
    "response.raise_for_status()  # Will raise an exception if there's an error\n",
    "\n",
    "# Parse the content using BeautifulSoup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "results = soup.find(id=\"site\").find_all('td', align='center')\n",
    "\n",
    "urls = []\n",
    "\n",
    "base_url = \"https://www.worldfootball.net\"\n",
    "\n",
    "for td in results:\n",
    "    a_tag = td.find('a', href=True)\n",
    "    if a_tag and 'report' in a_tag['href']:\n",
    "        URL = base_url + a_tag['href']\n",
    "        urls.append(URL)\n",
    "\n",
    "for URL in urls:\n",
    "    print(f\"Fetching data for: {URL}\")\n",
    "\n",
    "    # Fetch the webpage\n",
    "    response = requests.get(URL)\n",
    "    response.raise_for_status()  # Will raise an exception if there's an error\n",
    "\n",
    "    # Parse the content using BeautifulSoup\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    results = soup.find(id=\"site\").find_all(\"td\", class_=\"dunkel\")\n",
    "\n",
    "    attendance_td = None\n",
    "    for i, td in enumerate(results):\n",
    "        img = td.find('img', title='Attendance')\n",
    "        if img:\n",
    "            attendance_td = results[i + 1]  # Get the next <td> element after the img\n",
    "            break\n",
    "\n",
    "    if attendance_td:\n",
    "        attendance = attendance_td.get_text(strip=True)\n",
    "        print(f\"Attendance: {attendance}\")\n",
    "    else:\n",
    "        print(\"Attendance not found.\")\n",
    "    print(\"--------------------\")  # To separate results for clarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda1f893",
   "metadata": {},
   "source": [
    "# Next, try to also fetch day, date, GW, home team, away team data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "516b1aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Home team: KRC Genk\n",
      "Away team: SV Zulte Waregem\n",
      "Weekday: Saturday\n",
      "Date: 14. January 2023\n",
      "Time: 19:45\n",
      "Attendance: 14.111\n",
      "\n",
      "========================================\n",
      "\n",
      "Home team: Millwall FC\n",
      "Away team: Tranmere Rovers\n",
      "Weekday: Saturday\n",
      "Date: 19. January 2008\n",
      "Time: 15:00\n",
      "Attendance: 8.925\n",
      "\n",
      "========================================\n",
      "\n",
      "Home team: Ipswich Town\n",
      "Away team: Fleetwood Town\n",
      "Weekday: Sunday\n",
      "Date: 9. May 2021\n",
      "Time: 12:00\n",
      "Attendance: without spectators.\n",
      "\n",
      "========================================\n",
      "\n",
      "Home team: APOEL Nikosia\n",
      "Away team: Anorthosis Famagusta\n",
      "Weekday: Monday\n",
      "Date: 12. December 2016\n",
      "Time: 17:00\n",
      "Attendance not found.\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "# List of URLs\n",
    "urls = [\n",
    "    \"https://www.worldfootball.net/report/eerste-klasse-a-2022-2023-krc-genk-sv-zulte-waregem/\",\n",
    "    \"https://www.worldfootball.net/report/league-one-2007-2008-millwall-fc-tranmere-rovers/\",\n",
    "    \"https://www.worldfootball.net/report/league-one-2020-2021-ipswich-town-fleetwood-town/\",\n",
    "    \"https://www.worldfootball.net/report/first-division-2016-2017-apoel-nikosia-anorthosis-famagusta-fc/\"\n",
    "]\n",
    "\n",
    "# Loop through each URL in the list\n",
    "for URL in urls:\n",
    "    # Fetch the webpage\n",
    "    response = requests.get(URL)\n",
    "    response.raise_for_status()  # Will raise an exception if there's an error\n",
    "\n",
    "    # Parse the content using BeautifulSoup\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    results1 = soup.find(id=\"site\").find_all(\"th\", align=\"center\")\n",
    "    results2 = soup.find(id=\"site\").find_all(\"td\", class_=\"dunkel\")\n",
    "\n",
    "    for i, th in enumerate(results1):\n",
    "        a_tag = th.find('a', href=True)\n",
    "        if a_tag:\n",
    "            if i == 0:\n",
    "                print(\"Home team:\", a_tag['title'])\n",
    "            elif i == 2:\n",
    "                print(\"Away team:\", a_tag['title'])\n",
    "\n",
    "    # Regular expression pattern to extract weekday, date, and time\n",
    "    pattern = r\"(\\w+day), (\\d{1,2}\\. \\w+ \\d{4})(\\d{2}:\\d{2})\"\n",
    "\n",
    "    match = re.search(pattern, results1[1].text)\n",
    "\n",
    "    if match:\n",
    "        weekday = match.group(1)  # Extracting the weekday\n",
    "        date = match.group(2)    # Extracting the date\n",
    "        time = match.group(3)    # Extracting the time\n",
    "        \n",
    "        print(f\"Weekday: {weekday}\")\n",
    "        print(f\"Date: {date}\")\n",
    "        print(f\"Time: {time}\")\n",
    "    else:\n",
    "        print(\"Pattern not found in the text.\")\n",
    "\n",
    "    attendance_td = None\n",
    "    for i, td in enumerate(results2):\n",
    "        img = td.find('img', title='Attendance')\n",
    "        if img:\n",
    "            attendance_td = results2[i + 1]  # Get the next <td> element after the img\n",
    "            break\n",
    "\n",
    "    if attendance_td:\n",
    "        attendance = attendance_td.get_text(strip=True)\n",
    "        print(f\"Attendance: {attendance}\")\n",
    "    else:\n",
    "        print(\"Attendance not found.\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*40 + \"\\n\")  # To separate the results from different URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e5b3aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
